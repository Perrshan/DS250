---
title: "Client Report - Project 4"
subtitle: "Course DS 250"
author: "Xave Perry"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
#| label: libraries
#| include: false
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import plotly.graph_objects as go
import sqlite3
```


## Elevator pitch

_Using AI, I was able to find specific features of homes that can accuratly predict whether a home was built before or after 1980. Some of those things were the number of bathrooms, the total number of living space in the home, and the architecture style of the home. You would be surprised to see how many homes that are rated as great quality or in good condition do not vary as much as you think they would throughout the late 1800's and the early 1900's. It is also surprisling comprehensive to build a basic AI model, and studying this project can teach you a lot about how you can develop your own AI models!_

```{python}
#| label: project data
#| code-summary: Read and format project data
# Include and execute your code here
df = pd.read_csv("https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv")

```

## Potential Feature Charts

__Create 2-3 charts that evaluate potential relationships between the home variables and before1980.__

_I used averages of data and also counts of data to find relationships between different features of homes to see which ones show the highest chance of the prediction model being the most accurate. The box plot I created showed the average living space of homes before and after 1980 and there were clear differences in both categories. I know this would help the model predict which homes are most likely built before 1980 since there was a great difference in the averages. I also included bar charts and the information I was looking for was the ratio of before and after 1980 data and kept the highest difference in the counts._

```{python}
#| label: Q1
#| code-summary: Read and format data
# Include and execute your code here

with sqlite3.connect('your_database.db') as con:
    # Write DataFrame to SQLite
    df.to_sql('home_data', con, index=False, if_exists='replace')

    # Query and display results
    q_livearea = '''
    SELECT yrbuilt, AVG(livearea) AS AVG_livearea, before1980
    FROM home_data
    GROUP BY yrbuilt;
    '''

    q_quality = '''
    SELECT before1980, 'Quality A' AS quality_type, SUM(quality_A) AS count
    FROM home_data
    GROUP BY quality_type, before1980

    UNION ALL

    SELECT before1980, 'Quality C' AS quality_type, SUM(quality_C) AS count
    FROM home_data
    GROUP BY quality_type, before1980

    UNION ALL

    SELECT before1980, 'Quality D' AS quality_type, SUM(quality_D) AS count
    FROM home_data
    GROUP BY quality_type, before1980;
    '''

    q_condition = '''

    SELECT before1980, 'Very Good' AS condition, SUM(condition_VGood) AS count
    FROM home_data
    GROUP BY condition, before1980

    UNION ALL

    SELECT before1980, 'Good' AS condition, SUM(condition_Good) AS count
    FROM home_data
    GROUP BY condition, before1980;
    '''

    q_garage = '''

    SELECT before1980, 'Detatched' AS garage_type, SUM(gartype_Det) AS count
    FROM home_data
    GROUP BY garage_type, before1980

    UNION ALL

    SELECT before1980, 'Car Port' AS garage_type, SUM(gartype_CP) AS count
    FROM home_data
    GROUP BY garage_type, before1980

    UNION ALL

    SELECT before1980, 'None' AS garage_type, SUM(gartype_None) AS count
    FROM home_data
    GROUP BY garage_type, before1980;
    '''

    q_arc = '''

    SELECT before1980, 'CONVERSIONS' AS arc_style, SUM("arcstyle_CONVERSIONS") AS count
    FROM home_data
    GROUP BY arc_style, before1980

    UNION ALL

    SELECT before1980, 'ONE AND HALF-STORY' AS arc_style, SUM("arcstyle_ONE AND HALF-STORY") AS count
    FROM home_data
    GROUP BY arc_style, before1980

    UNION ALL

    SELECT before1980, 'ONE-STORY' AS arc_style, SUM("arcstyle_ONE-STORY") AS count
    FROM home_data
    GROUP BY arc_style, before1980

    UNION ALL

    SELECT before1980, 'TWO-STORY' AS arc_style, SUM("arcstyle_TWO-STORY") AS count
    FROM home_data
    GROUP BY arc_style, before1980;
    '''
    
    result_livearea = pd.read_sql_query(q_livearea, con)
    result_quality = pd.read_sql_query(q_quality, con)
    result_condition = pd.read_sql_query(q_condition, con)
    result_garage = pd.read_sql_query(q_garage, con)
    result_arc = pd.read_sql_query(q_arc, con)

```

_This is a box plot showing the differences in the living area of homes before and after 1980. The difference is clear and there is not much intersection._

```{python}
#| label: Q1 box plot
#| code-summary: show box plot
#| fig-cap: "Living Area Box Plot"
#| fig-align: center
# Include and execute your code here

chart = px.box(
    result_livearea,
    x="before1980",
    y="AVG_livearea",
    labels={'AVG_livearea': 'Average Live Area', 'before1980': 'Before 1980'},
    title='Living Area Before and After 1980'
)

chart.update_xaxes(tickvals=[0, 1], ticktext=['After 1980', 'Before 1980'])

chart.show()
```

_These are all box plots that show the different counts of each of these ratings or features to compare them between before and after 1980._

```{python}
#| label: Q1 chart A
#| code-summary: show bar chart
#| fig-cap: "Quality Bar Chart"
#| fig-align: center
# Include and execute your code here
chart = px.bar(
    result_quality,
    x="quality_type",
    y="count",
    color="before1980",
    barmode="group",  # This ensures bars are grouped by "before1980"
    labels={'count': 'Count', 'quality_type': 'Quality', 'before1980': 'Before 1980'},
    title='Quality of Homes Before and After 1980'
)

chart.show()
```

```{python}
#| label: Q1 chart B
#| code-summary: show bar chart
#| fig-cap: "Condition Bar Chart"
#| fig-align: center
# Include and execute your code here
chart = px.bar(
    result_condition,
    x="condition",
    y="count",
    color="before1980",
    barmode="group",  # This ensures bars are grouped by "before1980"
    labels={'count': 'Count', 'condition': 'Condition', 'before1980': 'Before 1980'},
    title='Condition of Homes Before and After 1980'
)

chart.show()
```

```{python}
#| label: Q1 chart C
#| code-summary: show bar chart
#| fig-cap: "Garage Type Bar Chart"
#| fig-align: center
# Include and execute your code here
chart = px.bar(
    result_garage,
    x="garage_type",
    y="count",
    color="before1980",
    barmode="group",  # This ensures bars are grouped by "before1980"
    labels={'count': 'Count', 'garage_type': 'Garage Type', 'before1980': 'Before 1980'},
    title='Garage Types Before and After 1980'
)

chart.show()
```

```{python}
#| label: Q1 chart D
#| code-summary: show bar chart
#| fig-cap: "Arc Bar Chart"
#| fig-align: center
# Include and execute your code here
chart = px.bar(
    result_arc,
    x="arc_style",
    y="count",
    color="before1980",
    barmode="group",  # This ensures bars are grouped by "before1980"
    labels={'count': 'Count', 'arc_style': 'Arc Style', 'before1980': 'Before 1980'},
    title='Arc Styles Before and After 1980'
)

chart.show()
```

## Random Forest Model

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.__

_The algorithm that I found was best for the data that was provided was the Random Forest model. And I decided to use a wide varity of features with one of the most important ones being the living area of each home. I found that was a great feature to help the prediction models. I also tried to use a logistic regression, SVM, gradiant boosting, and KNN models to test out the data.

```{python}
#| label: Q2
#| code-summary: Read and format data, prepare model data
# Include and execute your code here
# Read data
X = df[[
    'livearea', 'arcstyle_ONE-STORY', 'arcstyle_ONE AND HALF-STORY', 'gartype_Det', 'basement', 'totunits', 'stories', 'nocars', 'numbdrm' , 'numbaths'
]]

y = df['before1980']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

```

_This will print out different evaluation metrics like the accuracy, confusion matrix, and the Classification Report._

```{python}
#| label: Q2 Model Results
#| code-summary: Calculate accuracy, conf matrix, class rep
#| fig-cap: "Random Forest Model Results"
#| fig-align: center
# Include and execute your code here

# Initialize the Random Forest model
rf_model = RandomForestClassifier()

# Train the model using the training data
rf_model.fit(X_train, y_train)

# Make predictions on the test data
y_pred_rf = rf_model.predict(X_test)

conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
classification_rep_rf = classification_report(y_test, y_pred_rf)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
```

```{python}
#| label: Q2
#| code-summary: Read and format data, prepare model data
# Include and execute your code here
# Read data
X = df[[
    'sprice'
]]

y = df['before1980']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.34, random_state=76)

average_first_10_values = X_train.head(10).mean()

print("Average of the first 10 values in testing y:", average_first_10_values)

```

_This will print out different evaluation metrics like the accuracy, confusion matrix, and the Classification Report._

```{python}
#| label: Q2 Model Results
#| code-summary: Calculate accuracy, conf matrix, class rep
#| fig-cap: "Random Forest Model Results"
#| fig-align: center
# Include and execute your code here

# Initialize the Random Forest model
rf_model = RandomForestClassifier()

# Train the model using the training data
rf_model.fit(X_train, y_train)

# Make predictions on the test data
y_pred_rf = rf_model.predict(X_test)

conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
classification_rep_rf = classification_report(y_test, y_pred_rf)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
```

## Most Important Features

__Justify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.__

_When trying to find the best features for my model in the section labeled "Potential Feature Charts" I found one of the best features was the living area. As I actually was feature engineering my model I noticed that a lot of the columns in the data that I thought would be most beneficial were not giving me the accuracy that I was looking for, so for this section I graphed the additional features that I found most beneficial for my model including units, stories, and basement. I shared the unit graph as a line graph because it is easy to see the differences throughout the years, but the box plots of the stories, and bathrooms show a obvious difference in the averages similar to the living area graph I mentioned earlier that cannot be seen on a line graph._

```{python}
#| label: Q3
#| code-summary: Read and format data
# Include and execute your code here

with sqlite3.connect('your_database.db') as con:
    # Write DataFrame to SQLite
    df.to_sql('home_data', con, index=False, if_exists='replace')

    # Query and display results
    q_units = '''
    SELECT yrbuilt, AVG(totunits) AS AVG_units, before1980
    FROM home_data
    GROUP BY yrbuilt;
    '''

    q_stories = '''
    SELECT yrbuilt, AVG(stories) AS AVG_stories, before1980
    FROM home_data
    GROUP BY yrbuilt;
    '''

    q_baths = '''
    SELECT yrbuilt, AVG(stories) AS AVG_baths, before1980
    FROM home_data
    GROUP BY yrbuilt;
    '''

    result_units = pd.read_sql_query(q_units, con)
    result_stories = pd.read_sql_query(q_stories, con)
    result_baths = pd.read_sql_query(q_baths, con)

```

_Line graph showing the different number of units from 1873-2013._

```{python}
#| label: Q3 Line Chart
#| code-summary: plot line chart
#| fig-cap: "Line Chart of Average Units"
#| fig-align: center
# Include and execute your code here
chart = px.line(result_units,
    x="yrbuilt", 
    y="AVG_units",
    labels={'AVG_units': 'Average Number of Units', 'yrbuilt': 'Year Built'},
    title='Units per Home From 1800-2000'
)

chart.add_shape(
    go.layout.Shape(
        type="line",
        x0=1980,
        x1=1980,
        y0=0,
        y1=result_units['AVG_units'].max(),  # Adjust the y1 value as needed
        line=dict(color="red", width=2, dash="dash"),
    )
)

chart.show()
```

_Box plots showing the difference in means of stories, and bathrooms before and after 1980._

```{python}
#| label: Q3 Box Plot A
#| code-summary: show box plot
#| fig-cap: "Box Plot of Average Stories"
#| fig-align: center
# Include and execute your code here
chart = px.box(
    result_stories,
    x="before1980",
    y="AVG_stories",
    labels={'AVG_stories': 'Average Number of Stories', 'before1980': 'Before 1980'},
    title='Average Number of Stories Before and After 1980'
)

chart.update_xaxes(tickvals=[0, 1], ticktext=['After 1980', 'Before 1980'])

chart.show()

```

```{python}
#| label: Q3 Box Plot B
#| code-summary: show box plot
#| fig-cap: "Box Plots of Average Bathrooms"
#| fig-align: center
# Include and execute your code here
chart = px.box(
    result_baths,
    x="before1980",
    y="AVG_baths",
    labels={'AVG_baths': 'Average Number of Baths', 'before1980': 'Before 1980'},
    title='Average Number of Bathrooms Before and After 1980'
)

chart.update_xaxes(tickvals=[0, 1], ticktext=['After 1980', 'Before 1980'])

chart.show()

```

## Prediction Metrics

__Describe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.__

_I was able to make a model with 91% accuracy which means that after the model trained with 70% of the data the remaining 30% was tested and predictions were madde, the model could then predict if a home was built before or after 1980 with that accuracy. I also have the Confusion Matrix which shows the breakdown of where the model succeeded and failed in the positive or negative. There is a True Positive where the model accuratly predicted a home was built before 1980, True Negative where the model accuratly predicted a home was not built before 1980, False Positive where the model inaccuratly predicated a home was built before 1980, and finally False Negative where the model inaccuratly predicted a home was not built before 1980._

```{python}
#| label: Q3 Organized Data
#| code-summary: Show Model Data
#| tbl-cap: "MOdel Data"
#| tbl-cap-location: top
# Include and execute your code here
print("Accuracy - Random Forest:", accuracy_rf)
print('--------------------------------------------------------------')
print("Confusion Matrix - Random Forest:\n", conf_matrix_rf)

```

```{sql}
-- MySQL Workbench Forward Engineering

SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0;
SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0;
SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';

-- -----------------------------------------------------
-- Schema melaleuca_mock_store
-- -----------------------------------------------------

-- -----------------------------------------------------
-- Schema melaleuca_mock_store
-- -----------------------------------------------------
CREATE SCHEMA IF NOT EXISTS `melaleuca_mock_store` DEFAULT CHARACTER SET utf8 ;
USE `melaleuca_mock_store` ;

-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`member`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`member` (
  `member_id` INT NOT NULL AUTO_INCREMENT,
  `first_name` VARCHAR(45) NOT NULL,
  `last_name` VARCHAR(45) NOT NULL,
  `birth_date` DATE NULL,
  `start_date` DATE NOT NULL,
  `cancel_date` DATE NULL,
  `status` VARCHAR(45) NOT NULL,
  `email` VARCHAR(45) NOT NULL,
  `phone_number` VARCHAR(45) NOT NULL,
  PRIMARY KEY (`member_id`),
  UNIQUE INDEX `idMember_UNIQUE` (`member_id` ASC) VISIBLE)
ENGINE = InnoDB;


-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`cart`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`cart` (
  `cart_id` INT NOT NULL AUTO_INCREMENT,
  `member_id` INT NOT NULL,
  PRIMARY KEY (`cart_id`, `member_id`),
  INDEX `fk_cart_member1_idx` (`member_id` ASC) VISIBLE,
  CONSTRAINT `fk_cart_member1`
    FOREIGN KEY (`member_id`)
    REFERENCES `melaleuca_mock_store`.`member` (`member_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION)
ENGINE = InnoDB;


-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`shipping_address`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`shipping_address` (
  `shipping_address_id` INT NOT NULL AUTO_INCREMENT,
  `address_1` VARCHAR(45) NOT NULL,
  `address_2` VARCHAR(45) NULL,
  `state` CHAR(2) NOT NULL,
  `country` CHAR(3) NOT NULL,
  `city` VARCHAR(45) NOT NULL,
  `zip_code` CHAR(5) NOT NULL,
  `member_id` INT NOT NULL,
  PRIMARY KEY (`shipping_address_id`, `member_id`),
  INDEX `fk_shipping_address_member1_idx` (`member_id` ASC) VISIBLE,
  CONSTRAINT `fk_shipping_address_member1`
    FOREIGN KEY (`member_id`)
    REFERENCES `melaleuca_mock_store`.`member` (`member_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION)
ENGINE = InnoDB;


-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`order`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`order` (
  `order_id` INT NOT NULL AUTO_INCREMENT,
  `tracking_number` VARCHAR(45) NOT NULL,
  `current_location` VARCHAR(45) NULL,
  `expected_delivery_date` DATETIME NULL,
  `cart_id` INT NOT NULL,
  `member_id` INT NOT NULL,
  `latest_update` TIMESTAMP NULL,
  `shipping_address_id` INT NOT NULL,
  PRIMARY KEY (`order_id`, `cart_id`, `member_id`, `shipping_address_id`),
  INDEX `fk_order_cart1_idx` (`cart_id` ASC, `member_id` ASC) VISIBLE,
  INDEX `fk_order_shipping_address1_idx` (`shipping_address_id` ASC) VISIBLE,
  CONSTRAINT `fk_order_cart1`
    FOREIGN KEY (`cart_id` , `member_id`)
    REFERENCES `melaleuca_mock_store`.`cart` (`cart_id` , `member_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION,
  CONSTRAINT `fk_order_shipping_address1`
    FOREIGN KEY (`shipping_address_id`)
    REFERENCES `melaleuca_mock_store`.`shipping_address` (`shipping_address_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION)
ENGINE = InnoDB;


-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`product`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`product` (
  `product_id` INT NOT NULL AUTO_INCREMENT,
  `description` VARCHAR(250) NOT NULL,
  `price` DECIMAL(5,2) NOT NULL,
  `product_name` VARCHAR(45) NOT NULL,
  `weight` DECIMAL(4,2) NOT NULL,
  PRIMARY KEY (`product_id`),
  UNIQUE INDEX `idproduct_UNIQUE` (`product_id` ASC) VISIBLE,
  UNIQUE INDEX `product_name_UNIQUE` (`product_name` ASC) VISIBLE)
ENGINE = InnoDB;


-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`product_special`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`product_special` (
  `product_special_id` INT NOT NULL AUTO_INCREMENT,
  `price` DECIMAL(5,2) NOT NULL,
  `product_id` INT NOT NULL,
  PRIMARY KEY (`product_special_id`, `product_id`),
  UNIQUE INDEX `idproduct_UNIQUE` (`product_special_id` ASC) VISIBLE,
  INDEX `fk_special_product1_idx` (`product_id` ASC) VISIBLE,
  CONSTRAINT `fk_special_product1`
    FOREIGN KEY (`product_id`)
    REFERENCES `melaleuca_mock_store`.`product` (`product_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION)
ENGINE = InnoDB;


-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`payment_method`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`payment_method` (
  `payment_method_id` INT NOT NULL AUTO_INCREMENT,
  `card_type` VARCHAR(45) NOT NULL,
  `member_id` INT NOT NULL,
  PRIMARY KEY (`payment_method_id`, `member_id`),
  UNIQUE INDEX `idpayment_method_UNIQUE` (`payment_method_id` ASC) VISIBLE,
  INDEX `fk_payment_method_member1_idx` (`member_id` ASC) VISIBLE,
  CONSTRAINT `fk_payment_method_member1`
    FOREIGN KEY (`member_id`)
    REFERENCES `melaleuca_mock_store`.`member` (`member_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION)
ENGINE = InnoDB;


-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`service`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`service` (
  `service_id` INT NOT NULL AUTO_INCREMENT,
  `service_name` VARCHAR(45) NULL,
  `monthly_cost` DECIMAL(5,2) NULL,
  `member_id` INT NOT NULL,
  PRIMARY KEY (`service_id`, `member_id`),
  INDEX `fk_services_member1_idx` (`member_id` ASC) VISIBLE,
  UNIQUE INDEX `idservice_UNIQUE` (`service_id` ASC) VISIBLE,
  CONSTRAINT `fk_services_member1`
    FOREIGN KEY (`member_id`)
    REFERENCES `melaleuca_mock_store`.`member` (`member_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION)
ENGINE = InnoDB;


-- -----------------------------------------------------
-- Table `melaleuca_mock_store`.`cart_product`
-- -----------------------------------------------------
CREATE TABLE IF NOT EXISTS `melaleuca_mock_store`.`cart_product` (
  `cart_product_id` INT NOT NULL AUTO_INCREMENT,
  `cart_id` INT NOT NULL,
  `member_id` INT NOT NULL,
  `product_id` INT NOT NULL,
  PRIMARY KEY (`cart_product_id`, `cart_id`, `member_id`, `product_id`),
  INDEX `fk_cart_product_cart1_idx` (`cart_id` ASC, `member_id` ASC) VISIBLE,
  INDEX `fk_cart_product_product1_idx` (`product_id` ASC) VISIBLE,
  CONSTRAINT `fk_cart_product_cart1`
    FOREIGN KEY (`cart_id` , `member_id`)
    REFERENCES `melaleuca_mock_store`.`cart` (`cart_id` , `member_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION,
  CONSTRAINT `fk_cart_product_product1`
    FOREIGN KEY (`product_id`)
    REFERENCES `melaleuca_mock_store`.`product` (`product_id`)
    ON DELETE NO ACTION
    ON UPDATE NO ACTION)
ENGINE = InnoDB;


SET SQL_MODE=@OLD_SQL_MODE;
SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS;
SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS;

```

```{sql}
SET @member_id = 2;
SET @cart_id = 2;
SET @shipping_address_id = 2;

INSERT INTO member (first_name, last_name, start_date, status, email, phone_number) VALUES
('Linea', 'Swift', '2000-08-09', 'ACTIVE', 'Linea.Swift@fakemail.com', '250-800-5449');

INSERT INTO cart (member_id) VALUES
(@member_id);

INSERT INTO cart_product (cart_id, member_id, product_id) VALUES
(@cart_id,@member_id,6),
(@cart_id,@member_id,7),
(@cart_id,@member_id,8),
(@cart_id,@member_id,9),
(@cart_id,@member_id,10);

INSERT INTO shipping_address (address_1, city, state, zip_code, country, member_id) VALUES
('829 Cypress Avenue','Moss Landing', 'PA', '90123', 'USA', @member_id);

INSERT INTO melaleuca_mock_store.order (tracking_number, expected_delivery_date, cart_id, member_id, shipping_address_id) VALUES
('IN7765260235771584', '2024-03-20', @cart_id, @member_id, @shipping_address_id);


SELECT order_id, m.first_name, m.last_name, 
SUM(p.price) + 10.22 + (SUM(p.price)*0.06) AS ttl_price, SUM(p.weight) AS ttl_weight, o.expected_delivery_date
from melaleuca_mock_store.order o JOIN cart c ON
c.cart_id = o.cart_id JOIN cart_product cp ON
cp.cart_id = c.cart_id JOIN product p ON
p.product_id = cp.product_id JOIN `member` m ON
m.member_id = o.member_id
GROUP BY order_id, m.first_name, m.last_name, o.expected_delivery_date
HAVING o.order_id = 2;

INSERT INTO service (service_name, monthly_cost, member_id) VALUES
('Home Security', 299.99, 1)

INSERT INTO product_special (price, product_id) VALUES
(1.00, 1),
(0.50, 3)

SELECT order_id, m.first_name, m.last_name, 
SUM(CASE
		WHEN ps.product_id = p. product_id 
			THEN ps.price
      ELSE p.price
		END)*1.06 + 10.22 AS ttl_price, SUM(p.weight) AS ttl_weight, o.expected_delivery_date
from melaleuca_mock_store.order o JOIN cart c ON
c.cart_id = o.cart_id JOIN cart_product cp ON
cp.cart_id = c.cart_id JOIN product p ON
p.product_id = cp.product_id JOIN `member` m ON
m.member_id = o.member_id LEFT JOIN product_special ps ON
ps.product_id = p. product_id
GROUP BY order_id, m.first_name, m.last_name, o.expected_delivery_date
HAVING o.order_id = 1;


```